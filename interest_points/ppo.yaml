# PPO算法配置（匹配CARICAwarePPO）
algo:
  # 特征提取器配置
  feature_extractor:
    learning_rate: 3e-4
    weight_decay: 1e-5
    
  # 策略网络配置
  actor:
    learning_rate: 3e-4
    clip_ratio: 0.2  # PPO裁剪比例
    action_limit: 5.0  # 动作限制（m/s）
    weight_decay: 1e-5
    
  # 价值网络配置  
  critic:
    learning_rate: 3e-4
    clip_ratio: 0.2
    weight_decay: 1e-5
    
  # 训练参数
  entropy_loss_coefficient: 0.01  # 熵损失系数（鼓励探索）
  training_frame_num: 2048  # 每次训练的帧数（匹配代码中的frames_per_batch计算）
  training_epoch_num: 4  # 训练轮数
  num_minibatches: 8  # 小批次数量
  
  # GAE参数（匹配utils.py中的GAE）
  gamma: 0.99  # 折扣因子
  lambda: 0.95  # GAE lambda参数
  
  # 网络架构参数（匹配ppo.py中的网络结构）
  hidden_dim: 256  # 隐藏层维度
  
  # 兴趣点处理参数（匹配InterestPointProcessor）
  interest_point:
    max_points: 20  # 最大可见兴趣点数量（匹配代码中的max_visible_points）
    attention_heads: 4  # 注意力头数量
    hidden_dim: 64  # 兴趣点编码维度
    
  # 扫描感知参数
  scan_aware:
    scan_modulation_dim: 32  # 扫描调制维度
    interest_modulation_dim: 32  # 兴趣点调制维度
